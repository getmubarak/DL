{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch:  0   current predition : [0.45 0.75 0.95]\n",
      "Current Epoch:  1000   current predition : [1.24937979 2.14122399 2.77784872]\n",
      "Current Epoch:  2000   current predition : [1.20042229 2.11969506 2.82366601]\n",
      "Current Epoch:  3000   current predition : [1.15290926 2.09586925 2.86711256]\n",
      "Current Epoch:  4000   current predition : [1.11042022 2.07215036 2.90510067]\n",
      "Current Epoch:  5000   current predition : [1.07569428 2.05108986 2.93553869]\n",
      "Current Epoch:  6000   current predition : [1.04965627 2.03431564 2.95800286]\n",
      "Current Epoch:  7000   current predition : [1.03149962 2.02212185 2.97348661]\n",
      "Current Epoch:  8000   current predition : [1.01951566 2.01385019 2.98362553]\n",
      "Current Epoch:  9000   current predition : [1.01190331 2.00850373 2.99003268]\n",
      "Current Epoch:  10000   current predition : [1.00718835 2.00515631 2.99398827]\n",
      "Current Epoch:  11000   current predition : [1.00431431 2.00310238 2.99639461]\n",
      "Current Epoch:  12000   current predition : [1.00257964 2.00185776 2.99784523]\n",
      "Current Epoch:  13000   current predition : [1.00153894 2.00110928 2.99871488]\n",
      "Current Epoch:  14000   current predition : [1.00091684 2.00066121 2.9992345 ]\n",
      "Current Epoch:  15000   current predition : [1.00054577 2.00039373 2.99954436]\n",
      "Current Epoch:  16000   current predition : [1.00032472 2.00023431 2.99972892]\n",
      "Current Epoch:  17000   current predition : [1.00019315 2.00013938 2.99983876]\n",
      "Current Epoch:  18000   current predition : [1.00011487 2.0000829  2.99990411]\n",
      "Current Epoch:  19000   current predition : [1.00006831 2.0000493  2.99994298]\n",
      "Current Epoch:  20000   current predition : [1.00004062 2.00002931 2.9999661 ]\n",
      "Current Epoch:  21000   current predition : [1.00002415 2.00001743 2.99997984]\n",
      "Current Epoch:  22000   current predition : [1.00001436 2.00001036 2.99998801]\n",
      "Current Epoch:  23000   current predition : [1.00000854 2.00000616 2.99999287]\n",
      "Current Epoch:  24000   current predition : [1.00000508 2.00000366 2.99999576]\n",
      "Current Epoch:  25000   current predition : [1.00000302 2.00000218 2.99999748]\n",
      "Current Epoch:  26000   current predition : [1.00000179 2.0000013  2.9999985 ]\n",
      "Current Epoch:  27000   current predition : [1.00000107 2.00000077 2.99999911]\n",
      "Current Epoch:  28000   current predition : [1.00000063 2.00000046 2.99999947]\n",
      "Current Epoch:  29000   current predition : [1.00000038 2.00000027 2.99999969]\n",
      "Ground Truth:  [1.00000022 2.00000016 2.99999981]\n",
      "Rounded Truth:  [1. 2. 3.]\n",
      "Final weight X :  [0.99999965]\n",
      "Final weight Rec :  [1.00000029]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# 1. Data Preprocess and declare \n",
    "x = np.array([\n",
    "    [1,0,0],\n",
    "    [1,1,0],\n",
    "    [1,1,1]\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    [1],\n",
    "    [2],\n",
    "    [3]\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " We are only going to have two weights, Wx (Where we are going to multiple with the input x) and Wrec (Where we are going to multiple with the previous states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000022, 2.00000016, 2.99999981])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1.3 Starting Weights - however - \n",
    "# the best set of weights would be wx = 1 and wrec = 1\n",
    "wx = [0.2]\n",
    "wrec = [1.5]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Current_State_K = Previous_State K * Wrec + Current_Input_X * Wx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hyper Par\n",
    "number_or_epoch = 30000\n",
    "number_of_training_data = 3\n",
    "learning_rate_x = 0.02\n",
    "learning_rate_rec = 0.0006\n",
    "\n",
    "# np array\n",
    "states = np.zeros((3,4))\n",
    "grad_over_time = np.zeros((3,4))\n",
    "\n",
    "# 2. Start the Training\n",
    "for iter in range(number_or_epoch):\n",
    "\n",
    "    # 2.3 Feed Forward of the network\n",
    "    layer_1 = x[:,0] * wx + states[:,0] * wrec\n",
    "    states[:,1] = layer_1\n",
    "\n",
    "    layer_2 = x[:,1] * wx + states[:,1] * wrec\n",
    "    states[:,2] = layer_2\n",
    "\n",
    "    layer_3 = x[:,2] * wx + states[:,2] * wrec\n",
    "    states[:,3] = layer_3\n",
    " \n",
    "    cost = np.square(states[:,3] - y).sum() / number_of_training_data\n",
    "\n",
    "    grad_out = (states[:,3] - np.squeeze(y)) * 2 / number_of_training_data\n",
    "    grad_over_time[:,3] = grad_out\n",
    "    grad_over_time[:,2] = grad_over_time[:,3] * wrec\n",
    "    grad_over_time[:,1] = grad_over_time[:,2] * wrec\n",
    "\n",
    "    # NOTE: Do Not really need grad_over_time[:,0]\n",
    "    grad_over_time[:,0] = grad_over_time[:,1] * wrec\n",
    "\n",
    "    # \n",
    "    grad_wx = np.sum(grad_over_time[:,3] * x[:,2] + \n",
    "                     grad_over_time[:,2] * x[:,1]  + \n",
    "                     grad_over_time[:,1] * x[:,0])\n",
    "\n",
    "    grad_rec = np.sum(grad_over_time[:,3] * states[:,2] + \n",
    "                      grad_over_time[:,2] * states[:,1]  + \n",
    "                      grad_over_time[:,1] * states[:,0])\n",
    "    \n",
    "    wx = wx - learning_rate_x * grad_wx\n",
    "    wrec = wrec - learning_rate_rec * grad_rec\n",
    "\n",
    "    if iter%1000 == 0:\n",
    "        print('Current Epoch: ',iter, '  current predition :' ,layer_3)\n",
    "    \n",
    "\n",
    "# 3. Final Output and rounded resutls\n",
    "layer_1 = x[:,0] * wx + states[:,0] * wrec\n",
    "states[:,1] = layer_1\n",
    "\n",
    "layer_2 = x[:,1] * wx + states[:,1] * wrec\n",
    "states[:,2] = layer_2\n",
    "\n",
    "layer_3 = x[:,2] * wx + states[:,2] * wrec\n",
    "states[:,3] = layer_3\n",
    "\n",
    "print('Ground Truth: ',layer_3)\n",
    "print('Rounded Truth: ',np.round(layer_3))\n",
    "print(\"Final weight X : \",wx)\n",
    "print(\"Final weight Rec : \",wrec)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
