{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i1         h1\n",
    "\n",
    "           h2            o1\n",
    "\n",
    "i2         h3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i1 = 1\n",
    "i2 = 1\n",
    "\n",
    "i1->h1 = 0.8\n",
    "i1->h2 = 0.4\n",
    "i1->h3 = 0.3\n",
    "\n",
    "i2->h1 = 0.2\n",
    "i2->h2 = 0.9\n",
    "i2->h3 = 0.5\n",
    "\n",
    "\n",
    "h1->o1 = 0.3\n",
    "h2->o1 = 0.5\n",
    "h3->o1 = 0.9"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "forward propagation \n",
    "--------------------\n",
    "We sum the product of the inputs with their corresponding set of weights to arrive at the first values for the hidden layer.\n",
    "\n",
    "1 * 0.8 + 1 * 0.2 = 1\n",
    "1 * 0.4 + 1 * 0.9 = 1.3\n",
    "1 * 0.3 + 1 * 0.5 = 0.8\n",
    "\n",
    "applying S(x) to the three hidden layer sums, we get:\n",
    "\n",
    "S(1.0) = 0.73105857863\n",
    "S(1.3) = 0.78583498304\n",
    "S(0.8) = 0.68997448112\n",
    "\n",
    " we sum the product of the hidden layer results with the second set of weights\n",
    " \n",
    " 0.73 * 0.3 + 0.79 * 0.5 + 0.69 * 0.9 = 1.235\n",
    " \n",
    " we apply the activation function to get the final output result.\n",
    " \n",
    " S(1.235) = 0.7746924929149283\n",
    " \n",
    " Because we used a random set of initial weights, the value of the output neuron is off the mark; in this case by +0.77 (since the target is 0)\n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "forward propagation  using matrix\n",
    "----------------------------------\n",
    "\n",
    "(1 ,1) x 0.8,0.4,0.3 x 0.3\n",
    "         0.2,0.9,0.5   0.5\n",
    "                       0.9\n",
    "\n",
    "z= 1 x 0.8 + 1 x 0.2, 1x 0.4  + 1 x 0.9, 1 x 0.3 + 1 x 0.5 \n",
    "z = 1, 1.3, 0.8 \n",
    "\n",
    "s(Z)= 1 / (1 + e^-z)\n",
    "  = 1 / (1 + 2.71828^(-z))\n",
    "\n",
    "S(1.0) = 0.73105857863\n",
    "S(1.3) = 0.78583498304\n",
    "S(0.8) = 0.68997448112\n",
    "\n",
    "0.73, 0.79, 0.69 x 0.3\n",
    "                   0.5\n",
    "                   0.9\n",
    "        \n",
    "0.73 x 0.3 + 0.79 x 0.5 + 0.69 x 0.9\n",
    "0.219 + 0.395 + 0.621\n",
    "1.235\n",
    "1 / (1 + 2.71828^(-1.235))\n",
    "0.77\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "back propagation \n",
    "--------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Target = 0\n",
    "output sum = 1.235\n",
    "Calculated = 0.77   {sig(outputsun)}\n",
    "output sum margin of error= Target - calculated = -0.77\n",
    "\n",
    "Delta output sum = S'(output sum) * (output sum margin of error)\n",
    "Delta output sum = S'(1.235) * (-0.77)\n",
    "Delta output sum = (s * (1 - s)) * (-0.77)\n",
    "Delta output sum = (0.77 * (1 - 0.77)) * (-0.77)\n",
    "Delta output sum = (0.1771) * (-0.77)\n",
    "Delta output sum = -0.13439890643886018\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hidden result \n",
    "1 = 0.73105857863\n",
    "2 = 0.78583498304\n",
    "3 = 0.68997448112\n",
    "\n",
    "old weights\n",
    "w7 = 0.3\n",
    "w8 = 0.5\n",
    "w9 = 0.9\n",
    "\n",
    "Delta weights \n",
    "dw= delta output sum * hidden layer results\n",
    "dw = -0.1344 * [0.73105, 0.78583, 0.69997]\n",
    "dw = [-0.0983, -0.1056, -0.0941]\n",
    "\n",
    "new weight = old weight + Delta weight\n",
    "new w7 = 0.202\n",
    "new w8 = 0.394\n",
    "new w9 = 0.806"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Delta hidden sum = delta output sum * hidden-to-outer weights * S'(hidden sum)\n",
    "Delta hidden sum = -0.1344 * [0.3, 0.5, 0.9] * S'([1, 1.3, 0.8])\n",
    "Delta hidden sum = [-0.0403, -0.0672, -0.1209] * [0.1966, 0.1683, 0.2139]\n",
    "Delta hidden sum = [-0.0079, -0.0113, -0.0259] \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input 1 = 1\n",
    "input 2 = 1\n",
    "\n",
    "Delta weights = delta hidden sum * input\n",
    "Delta weights = [-0.0079, -0.0113, -0.0259] * [1, 1]\n",
    "Delta weights = [-0.0079, -0.0113, -0.0259, -0.0079, -0.0113, -0.0259]\n",
    "\n",
    "old w1 = 0.8\n",
    "old w2 = 0.4\n",
    "old w3 = 0.3\n",
    "old w4 = 0.2\n",
    "old w5 = 0.9\n",
    "old w6 = 0.5\n",
    "\n",
    "new w1 = 0.7921\n",
    "new w2 = 0.3887\n",
    "new w3 = 0.2741\n",
    "new w4 = 0.1921\n",
    "new w5 = 0.8887\n",
    "new w6 = 0.4741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old         new\n",
    "-----------------\n",
    "w1: 0.8     w1: 0.7921\n",
    "w2: 0.4     w2: 0.3887\n",
    "w3: 0.3     w3: 0.2741\n",
    "w4: 0.2     w4: 0.1921\n",
    "w5: 0.9     w5: 0.8887\n",
    "w6: 0.5     w6: 0.4741\n",
    "w7: 0.3     w7: 0.2020\n",
    "w8: 0.5     w8: 0.3940\n",
    "w9: 0.9     w9: 0.8060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://medium.com/@14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
