{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "to demonstrate the memory capability of the Vanilla LSTM. \n",
    "\n",
    "given a sequence of random integers as input, to output the value of a random integer at a specific time input step that is not specified to the model. For example, given the input sequence of random integers [5, 3, 2] and the chosen time step was the second value, then the expected output is 3. \n",
    "\n",
    "\n",
    "The output for the sequence is simply the encoded integer at a specific pre-defined location. This location must remain consistent for all examples generated for one model, so that the model can learn. For example, we can use the 2nd time step as the output of a sequence with 25 time steps by taking the encoded value directly from the encoded sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "# generate a sequence of random numbers in [0, n_features)\n",
    "def generate_sequence(length, n_features):\n",
    "  return [randint(0, n_features-1) for _ in range(length)]\n",
    "\n",
    "# one hot encode sequence\n",
    "def one_hot_encode(sequence, n_features):\n",
    "  encoding = list()\n",
    "  for value in sequence:\n",
    "    vector = [0 for _ in range(n_features)]\n",
    "    vector[value] = 1\n",
    "    encoding.append(vector)\n",
    "  return array(encoding)\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "  return [argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "# generate one example for an lstm\n",
    "def generate_example(length, n_features, out_index):\n",
    "  # generate sequence\n",
    "  sequence = generate_sequence(length, n_features)\n",
    "  # one hot encode\n",
    "  encoded = one_hot_encode(sequence, n_features)\n",
    "  # reshape sequence to be 3D\n",
    "  X = encoded.reshape((1, length, n_features))\n",
    "  # select output\n",
    "  y = encoded[out_index].reshape(1, n_features)\n",
    "  return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 25)                3600      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 3,860\n",
      "Trainable params: 3,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "length = 5\n",
    "n_features = 10\n",
    "out_index = 2 #<--- which time to predict\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(25, input_shape=(length, n_features)))\n",
    "model.add(Dense(n_features, activation= 'softmax' ))\n",
    "model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'acc' ])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 0, 9, 0, 4]]\n",
      "[9]\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.1545 - acc: 0.0000e+00\n",
      "[[7, 5, 8, 1, 9]]\n",
      "[8]\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.3502 - acc: 0.0000e+00\n",
      "[[4, 1, 1, 2, 2]]\n",
      "[1]\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.3093 - acc: 0.0000e+00\n",
      "[[8, 2, 8, 3, 8]]\n",
      "[8]\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.2427 - acc: 0.0000e+00\n",
      "[[3, 2, 3, 4, 6]]\n",
      "[3]\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.2973 - acc: 0.0000e+00\n",
      "[[9, 1, 4, 1, 6]]\n",
      "[4]\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.3675 - acc: 0.0000e+00\n",
      "[[9, 2, 1, 1, 3]]\n",
      "[1]\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.2953 - acc: 0.0000e+00\n",
      "[[8, 1, 8, 0, 9]]\n",
      "[8]\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.3521 - acc: 0.0000e+00\n",
      "[[3, 6, 0, 1, 6]]\n",
      "[0]\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.3985 - acc: 0.0000e+00\n",
      "[[9, 5, 2, 2, 8]]\n",
      "[2]\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.3279 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "for i in range(10): #000):\n",
    "  X, y = generate_example(length, n_features, out_index)\n",
    "  print([one_hot_decode(x) for x in X])\n",
    "  print(one_hot_decode(y))  \n",
    "  model.fit(X, y, epochs=1, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.000000\n",
      "Sequence: [[6, 9, 7, 9, 1]]\n",
      "Expected: [7]\n",
      "Predicted: [3]\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "correct = 0\n",
    "\n",
    "for i in range(10): #0):\n",
    "  X, y = generate_example(length, n_features, out_index)\n",
    "  yhat = model.predict(X)\n",
    "  if one_hot_decode(yhat) == one_hot_decode(y):\n",
    "    correct += 1\n",
    "    \n",
    "print( 'Accuracy: %f'  % ((correct/100)*100.0))\n",
    "# prediction on new data\n",
    "X, y = generate_example(length, n_features, out_index)\n",
    "\n",
    "yhat = model.predict(X)\n",
    "print( 'Sequence: %s'  % [one_hot_decode(x) for x in X])\n",
    "print( 'Expected: %s'  % one_hot_decode(y))\n",
    "print( 'Predicted: %s'  % one_hot_decode(yhat))   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Donâ€™t panic if the model gets it wrong. LSTMs are stochastic and it is possible that a single run of the model may converge on a solution that does not completely learn the problem. If this happens to you, try running the example a few more times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
